{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyparsing import conditionAsParseAction\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and convert to a dataframe\n",
    "data = 'winequality-red.csv'\n",
    "df = pd.read_csv(data, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   volatile acidity  citric acid  total sulfur dioxide  density  sulphates  \\\n",
      "0              0.70         0.00                  34.0   0.9978       0.56   \n",
      "1              0.88         0.00                  67.0   0.9968       0.68   \n",
      "2              0.76         0.04                  54.0   0.9970       0.65   \n",
      "3              0.28         0.56                  60.0   0.9980       0.58   \n",
      "4              0.70         0.00                  34.0   0.9978       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "#Feature Selection\n",
    "df = df.drop(['residual sugar', 'free sulfur dioxide', 'pH', 'fixed acidity', 'chlorides'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non Normalize Data\n",
    "X = df.iloc[:,:6]\n",
    "y = df.iloc[:,6]\n",
    "\n",
    "# Scaling the data\n",
    "standard = preprocessing.scale(X)\n",
    "\n",
    "# Normalizing the data\n",
    "df_norm = (standard - standard.min()) / (standard.max() - standard.min())\n",
    "df_norm = pd.DataFrame(df_norm)\n",
    "#Normalize Data\n",
    "X_norm = df_norm.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Spliting the data into training and testing sets (Normalize)\n",
    "X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Non Normalized Data ---------\n",
      "\n",
      "\n",
      "--Metricas--\n",
      " Mean squared error: 0.347944\n",
      " r2_score: 0.3922\n",
      " Mean Absolute Error: 0.4205\n",
      " explained_variance_score: 0.399871 \n",
      " precision: 0.392196\n",
      "---- Normalized Data ----\n",
      "\n",
      "\n",
      "--Metricas--\n",
      " Mean squared error: 0.349602\n",
      " r2_score: 0.3893\n",
      " Mean Absolute Error: 0.4217\n",
      " explained_variance_score: 0.396905 \n",
      " Precision:0.389300\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "\n",
    "# ----------- Non Normalized Data ---------\n",
    "print(\"---- Non Normalized Data ---------\\n\")\n",
    "\n",
    "# Training and testing data\n",
    "model = RandomForestRegressor(n_estimators = 500,random_state=0)\n",
    "\n",
    "# Training model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Testing model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n--Metricas--\")\n",
    "print(\" Mean squared error: {:.6f}\\n r2_score: {:.4f}\\n Mean Absolute Error: {:.4f}\\n explained_variance_score: {:.6f} \\n precision: {:.6f}\".format(mean_squared_error(y_test, y_pred),r2_score(y_test, y_pred),mean_absolute_error(y_test, y_pred),explained_variance_score(y_test, y_pred),model.score(X_test, y_test)))\n",
    "\n",
    "# ----------- Normalized Data ---------\n",
    "print(\"---- Normalized Data ----\\n\")\n",
    "# Training and testing data\n",
    "model = RandomForestRegressor(n_estimators = 500,random_state=0)\n",
    "\n",
    "# Training model\n",
    "model.fit(X_train_norm, y_train_norm)\n",
    "\n",
    "# Testing model\n",
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "print(\"\\n--Metricas--\")\n",
    "print(\" Mean squared error: {:.6f}\\n r2_score: {:.4f}\\n Mean Absolute Error: {:.4f}\\n explained_variance_score: {:.6f} \\n Precision:{:.6f}\".format(mean_squared_error(y_test_norm, y_pred),r2_score(y_test_norm, y_pred),mean_absolute_error(y_test_norm, y_pred),explained_variance_score(y_test_norm, y_pred),model.score(X_test_norm, y_test_norm)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "772f66837d71377a9e91bdceabcb0d3cb18014278592638634865ba084916021"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
